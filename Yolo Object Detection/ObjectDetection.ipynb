{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7c9706-7620-4170-b924-3885f43e65ef",
   "metadata": {},
   "source": [
    "# Object Detection using Yolo-RS\n",
    "The following is the creation of an object detection framework using Yolo-RS.\n",
    "## Backbone\n",
    "Firstly, the backbone is created using CBS and RS blocks, the detailed description is provided as follows:\n",
    "### RS BLocks\n",
    "https://www.sciencedirect.com/science/article/pii/S105120042400513X\n",
    "### CBS\n",
    "https://www.researchgate.net/figure/YOLOv8-network-structure-diagram-CBS-is-composed-of-Convolution-Batch-Normalization_fig2_371983458\n",
    "### torch.nn\n",
    "https://medium.com/@sahin.samia/mastering-the-basics-of-torch-nn-a-comprehensive-guide-to-pytorchs-neural-network-module-9f2d704e8c7f\n",
    "### Python Super()\n",
    "https://www.geeksforgeeks.org/python-super/\n",
    "### SPP\n",
    "https://nanostring.com/products/atomx-spatial-informatics-platform/cosmx-and-atomx-the-first-fully-integrated-single-cell-spatial-solution/?utm_source=bing&utm_medium=cpc&utm_campaign=cosmx&utm_source=bing&utm_medium=cpc&utm_campaign=cosmx&utm_id=SMI_CombinedTier_Search&msclkid=2f0fdb9b7b0611cc8617bc5c805cf0fb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f43ac4-110a-4356-af3c-d9e2f60f9421",
   "metadata": {},
   "source": [
    "# BackBone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5a325-2aa2-41df-8e04-8c2716162302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0e57a-6fd1-42a5-978f-62f65ea16803",
   "metadata": {},
   "source": [
    "### CBS Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cda682-76f5-41b0-9adc-2be1f2eb9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBS (nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 0):\n",
    "        super(CBS, self).__init__()\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d (in_channels, out_channels, kernel_size, stride, padding, bias = False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.silu = nn.SiLU()\n",
    "    def forward(self, x):\n",
    "        return self.silu(self.bn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9e8b8-8a0b-4132-887b-084385b3f4ff",
   "metadata": {},
   "source": [
    "### RS Block1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98323130-b3f7-44ed-b3ea-c5e29a66473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSB1(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(RSB1, self).__init__()\n",
    "        c_half = in_channels // 2 #C/2 channels\n",
    "        self.downsample = CBS(in_channels, in_channels, kernel_size = 3, stride = 2, padding = 1) ## downsampling\n",
    "        self.br1 = CBS(in_channels, c_half, kernel_size = 1) # Reduced channels\n",
    "        self.br2 = nn.Sequential (\n",
    "            CBS(c_half, c_half, kernel_size = 3, padding = 1), #fearture extraction\n",
    "            CBS(c_half, c_half, kernel_size = 3, padding = 1), #fearture extraction\n",
    "            CBS(c_half, c_half, kernel_size = 3, padding = 1) #fearture extraction\n",
    "        )\n",
    "        self.final_cbs = CBS(in_channels, in_channel, kernel_size = 1) #final transformation\n",
    "        self.shortcut = CBS(in_channels, in_channels, kernel_size = 3, stride = 2, padding = 1)# identity shortcut\n",
    "    def forward (self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        x = self.downsample(x)\n",
    "        br1_out = self.br1(x)\n",
    "        br2_out = self.br2(br1_out)\n",
    "        x = torch.cat((br1_out, br2_out), dim = 1) #concatinating along channel dimensions\n",
    "        return self.final_cbs(x) + identity #Residual connection\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09775274-151d-4b1a-a08b-e1686b3201b6",
   "metadata": {},
   "source": [
    "### RS Block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065e502-e166-42f9-8fd3-219d774d2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSB2(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(RSB2, self).__init__()\n",
    "        c_half = in_channels // 2\n",
    "        self.red = CBS (in_channels, c_half, kernel_size = 1)\n",
    "        self.br1 = nn.Sequential (\n",
    "            CBS(c_half, c_half, kernel_size = 3, padding = 1), #fearture extraction\n",
    "            CBS(c_half, c_half, kernel_size = 3, padding = 1) #fearture extraction\n",
    "        )\n",
    "        self.br2 = nn. Sequential(\n",
    "        CBS(c_half, c_half, kernel_size = 3, padding = 1), #fearture extraction\n",
    "        CBS(c_half, c_half, kernel_size = 3, padding = 1) #fearture extraction\n",
    "        )\n",
    "        self.final_cbs = CBS(in_channels, in_channels, kernel_size = 1)\n",
    "    def forward(self, x):\n",
    "        identity = x #Direct residual connection\n",
    "        x = self.red(x)\n",
    "        br1_out = self.br1(x)\n",
    "        br2_out = self.br2(x)\n",
    "        x = torch.cat((br1_out, br2_out), dim = 1)\n",
    "        return self.final_cbs(x) + identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7b096-83e6-4314-b113-3761af196832",
   "metadata": {},
   "source": [
    "### SPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa6d3b-d370-4be7-8148-a02ed70086e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPP(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SPP, self).__init__()\n",
    "        self.cbs = CBS(in_channels * 4, in_channels, kernel_size = 1)\n",
    "    def forward (self, x):\n",
    "        x1 = F.max_pool2d(x, 5, stride = 1, padding = 2)\n",
    "        x2 = F.max_pool2d(x, 9, stride = 1, padding = 4)\n",
    "        x3 = F.max_pool2d(x, 13, stride = 1, padding = 6)\n",
    "        x = torch.cat([x, x1, x2, x3], dim = 1)\n",
    "        x = self.cbs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfc7d9-7028-4a8d-a480-284b39ac2514",
   "metadata": {},
   "source": [
    "### Implementing Backbone\n",
    "Now the backbone would be assembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9024f202-9329-4d22-bd5d-acdd0b254ff6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBB\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(BB, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class BB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BB, self).__init__()\n",
    "        self.cbs1 = CBS(3, 32)\n",
    "        self.RSB1_64 = RSB1(64)\n",
    "        self.RSB1_128 = RSB1(128)\n",
    "        self.RSB1_256 = RSB1(256)\n",
    "        self.RSB1_256 = RSB1(256)\n",
    "        self.RSB1_512 = RSB1(512)\n",
    "        self.RSB1_512 = RSB1(512)\n",
    "        self.RSB1_1024 = RSB1(1024)\n",
    "        self.RSB1_1024 = RSB1(1024)\n",
    "        self.spp = SPP(1024)\n",
    "    def forward(self, x):\n",
    "        x = self.cbs1(x)\n",
    "        x = self.RSB1_64(x)\n",
    "        x = self.RSB1_128(x)\n",
    "        x = self.RSB1_256(x)\n",
    "        x = self.RSB1_256(x)\n",
    "        x = self.RSB1_512(x)\n",
    "        x = self.RSB1_512(x)\n",
    "        x = self.RSB1_1024(x)\n",
    "        x = self.RSB1_1024(x)\n",
    "        x = self.spp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a99a3-6075-4fcb-9083-75913eeb40af",
   "metadata": {},
   "source": [
    "# Neck\n",
    "Now we will move towards the neck module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d8d669-2bd6-40d4-914e-2778dbd3d1c3",
   "metadata": {},
   "source": [
    "### Down Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e9329-edb8-4dad-99bf-07b968f987c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##downsamploing block using CBS with stride 2\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.cbs = CBS(in_channels, out_channels, stride = 2)\n",
    "    def forward(self, x):\n",
    "        return self.cbs(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c872c-2b9b-4207-ab48-8e1e88edb2ae",
   "metadata": {},
   "source": [
    "### Up Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e38a2c-52aa-4dbe-9ee7-f256baa44565",
   "metadata": {},
   "outputs": [],
   "source": [
    "##upsample using CBS followed by upsampling layer\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Up, self).__init__()\n",
    "        self.cbs = CBS(in_channels, out_channels)\n",
    "        self.up_s = nn.Upsample(scale_factor = 2, mode = 'nearest')\n",
    "    def forward(self, x):\n",
    "        x = self.cbs(x)\n",
    "        return self.up_s(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d4e23-d683-4eb8-a4f8-29f1dc1c040f",
   "metadata": {},
   "source": [
    "### Neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe9f25b-0954-4ea9-b8d2-830cc4b25202",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3482084984.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 15\u001b[1;36m\u001b[0m\n\u001b[1;33m    def forward(self, x):\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "### Neck module, connecting head and backbone\n",
    "class Neck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Neck, self).__init__()\n",
    "        self.ops = nn.ModuleList([\n",
    "            Down(1024, 512),\n",
    "            Down(512, 256),\n",
    "            CBS(256, 128),\n",
    "            CBS(128, 64),\n",
    "            Up(64, 128),\n",
    "            Up(128, 256),\n",
    "            CBS(256, 512),\n",
    "            CBS(512, 1024)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for op in self.ops:\n",
    "            x = op(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c73faa-ca41-4c1b-a8b8-2846a80b1633",
   "metadata": {},
   "source": [
    "# Yolo Head\n",
    "Finally, we would create the head part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58113f21-fbcf-449d-876c-bafc36aebb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(YoloHead, self).__init__()\n",
    "        self.cbs1 = CBS(in_channels, in_channels // 2)\n",
    "        self.cbs2 = CBS(in_channels // 2, in_channels // 2)\n",
    "        self.obj = nn.Conv2d(in_channels // 2, 1, kernel_size = 1) #objectness\n",
    "        self.reg = nn.Conv2d(in_channels // 2, 4, kernel_size = 1) # Bounding box\n",
    "        self.cls = nn.Conv2d(in_channels // 2, num_classes, kernel_size = 1) # Class score\n",
    "    def forward(self, x):\n",
    "        x = self.cbs1(x)\n",
    "        x = self.cbs2(x)\n",
    "        obj_out = self.obj(x) #objectness regression\n",
    "        reg_out = self.reg(x) #bouding box regression\n",
    "        cls_out = self.cls(x) #class regressison\n",
    "\n",
    "        return obj_out, reg_out, cls_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ffb47-a96e-4e76-b42d-d4826e384803",
   "metadata": {},
   "source": [
    "### Main and program running\n",
    "Finally, we call in main and run the program\n",
    "### os\n",
    "https://www.geeksforgeeks.org/os-module-python-examples/\n",
    "### Transform\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html\n",
    "### readlines()\n",
    "https://www.w3schools.com/python/ref_file_readlines.asp\n",
    "### dataloader\n",
    "https://pytorch.org/docs/stable/data.html\n",
    "### criterion\n",
    "https://nn.readthedocs.io/en/rtd/criterion/index.html\n",
    "### zero_grad()\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n",
    "### backward\n",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
    "### step()\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html\n",
    "### device\n",
    "https://www.geeksforgeeks.org/python-tensorflow-device/\n",
    "### eval()\n",
    "https://www.geeksforgeeks.org/eval-in-python/\n",
    "### ToTensor\n",
    "https://pytorch.org/vision/master/generated/torchvision.transforms.ToTensor.html\n",
    "### Transform.Normalize (mean, std)\n",
    "https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html\n",
    "### torch.cuda\n",
    "http://pytorch.org/docs/stable/cuda.html\n",
    "### MSELoss()\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html\n",
    "### YoloLoss\n",
    "https://docs.ultralytics.com/reference/utils/loss/#ultralytics.utils.loss.VarifocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaba792-1d0b-4a07-8dcc-1c50dd15db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo\n",
    "class Yolo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Yolo, self).__init__()\n",
    "        self.backbone = BB()\n",
    "        self.neck = Neck()\n",
    "        self.head = YoloHead (1024, 80)\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.neck(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d277ae9-4f90-4e1b-be5b-32664ed011b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolodataset(Dataset):\n",
    "    def __init__(self, img_dir, ann_dir, transform = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.ann_dir = ann_dir\n",
    "        self.transform = transform\n",
    "        self.img_files = os.listdir (img_dir)\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        ann_path = os.path.join(self.ann_dir, self.img_file[idx].replace(\".jpg\", \".txt\"))\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        with open(ann_path, \"r\") as f:\n",
    "            anns = f.readlines()\n",
    "        anns = [list(map(float, ann.strip().split())) for an in ann]\n",
    "        return img, torch.tensor(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e157d-87cc-4c58-a9d7-e0bd7a1b2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for img, targets in dataloader:\n",
    "        img, targets = img.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5e7ba-ac9b-42e7-801d-6f3c25b294bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for img, targets in dataloader:\n",
    "            img, targets = img.to(device), targets.to(device)\n",
    "            outputs = model(img)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e9437-e809-4c64-afe8-7eab8a9eea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for img, _ in dataloader:\n",
    "            img = img.to(device)\n",
    "            outputs = model(img)\n",
    "            predictions.append(outputs)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901731f-6be8-4e58-82f3-9fcb611684f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_img_dir = \"/\"\n",
    "    train_ann_dir = \"/\"\n",
    "    val_img_dir = \"/\"\n",
    "    val_ann_dir = \"/\"\n",
    "    test_img_dir = \"/\"\n",
    "    test_ann_dir = \"/\"\n",
    "    #defining transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((416, 416)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    #Datasets creation\n",
    "    train_dataset = YoloDataset(train_img_dir, train_ann_dir, transform)\n",
    "    val_dataset = YoloDataset(val_img_dir, val_ann_dir, transform)\n",
    "    test_dataset = YoloDataset(test_img_dir, test_ann_dir, transform)\n",
    "    #Loader creations\n",
    "    train_loader = DataLoader(train_dataset, batch_size = 8, shuffle = True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = True)\n",
    "\n",
    "    #Model Initialization, optimizers and Loss_func\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Yolo().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    criterion = nn.MSELoss() #loss function\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1} / {num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "    #model predictions\n",
    "    predictions = test(model, test_loader, device)\n",
    "    print(\"Testing\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
